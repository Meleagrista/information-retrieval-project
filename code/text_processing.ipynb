{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "0323e25d",
   "metadata": {},
   "outputs": [],
   "source": [
    "demo = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1b77b7f",
   "metadata": {},
   "source": [
    "# IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "f1220bd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "from requests import Request, Session\n",
    "from requests.exceptions import ConnectionError, Timeout, TooManyRedirects\n",
    "import json\n",
    "import pprint \n",
    "import os\n",
    "\n",
    "# Import progress bar module\n",
    "from alive_progress import alive_bar\n",
    "\n",
    "# Import time and sys modules\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Import BoardGameGeek client\n",
    "from boardgamegeek import BGGClient\n",
    "\n",
    "# Create an instance of the BoardGameGeek client\n",
    "bgg = BGGClient()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b579a8b",
   "metadata": {},
   "source": [
    "# EXTRACTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2face6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the hot items in the 'boardgame' category from BoardGameGeek\n",
    "hot_items = bgg.hot_items('boardgame')\n",
    "\n",
    "# Create an empty dictionary to store items that encounter errors\n",
    "miss = {}\n",
    "\n",
    "# Create an empty list to store the extracted data\n",
    "data = []\n",
    "\n",
    "count = 0\n",
    "\n",
    "# Iterate over each hot item\n",
    "for item in hot_items:\n",
    "    try:\n",
    "        count = count + 1\n",
    "        print(f'[{count}]')\n",
    "        \n",
    "        # Retrieve the game details, including comments, for the current item\n",
    "        game = bgg.game(game_id=item.id, comments=True)\n",
    "        \n",
    "        # Create a progress bar with the length of the comments\n",
    "        with alive_bar(len(game.comments), force_tty=True) as bar:\n",
    "            \n",
    "            # Iterate over each comment in the game\n",
    "            for comment in game.comments:\n",
    "                # Create a dictionary to store the comment data\n",
    "                com_data = {\n",
    "                    \"id\": item.id,\n",
    "                    \"title\": item.name,\n",
    "                    \"user\": comment.commenter,\n",
    "                    \"comment\": comment.comment,\n",
    "                    \"rating\": comment.rating\n",
    "                }\n",
    "                \n",
    "                # Append the comment data to the list\n",
    "                data.append(com_data)\n",
    "                \n",
    "                # time.sleep(0.01)\n",
    "                \n",
    "                # Update the progress bar\n",
    "                bar()\n",
    "        \n",
    "    except:\n",
    "        # If an error occurs, print 'error' and add the item to the 'miss' dictionary\n",
    "        print('ERROR - Skipping the rest of the comments...\\n')\n",
    "        miss[item.id] = item.name\n",
    "\n",
    "if demo:\n",
    "    # Specify the folder path where you want to save the file\n",
    "    folder_path = r'C:\\Users\\Usuario\\Documents\\JupyterFolder\\unimi_files\\IR\\files_csv\\version_demo'\n",
    "    # Specify the filename\n",
    "    filename = \"comment_data_demo.json\"\n",
    "else:\n",
    "    folder_path = r'C:\\Users\\Usuario\\Documents\\JupyterFolder\\unimi_files\\IR\\files_csv'\n",
    "    filename = \"comment_data.json\"\n",
    "\n",
    "# Construct the full file path\n",
    "file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "# Save the extracted data to the JSON file\n",
    "with open(file_path, 'w') as f:\n",
    "    json.dump(data, f, indent=2)  # indent=2 is not needed but makes the file human-readable if the data is nested"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f565491",
   "metadata": {},
   "source": [
    "# WRANGLING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ad4bc111",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Amount of comments before any formatting: 72651\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>user</th>\n",
       "      <th>comment</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>390478</td>\n",
       "      <td>Gloomhaven: Second Edition</td>\n",
       "      <td>amusedleg</td>\n",
       "      <td>Day 1 of the GH 2.0 campaign.  Can't wait.</td>\n",
       "      <td>n/a</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                       title       user  \\\n",
       "0  390478  Gloomhaven: Second Edition  amusedleg   \n",
       "\n",
       "                                      comment rating  \n",
       "0  Day 1 of the GH 2.0 campaign.  Can't wait.    n/a  "
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Set the display option to show all columns in pandas DataFrame\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "if demo:\n",
    "    # Specify the folder path where you want to save the file\n",
    "    folder_path = r'C:\\Users\\Usuario\\Documents\\JupyterFolder\\unimi_files\\IR\\files_csv\\version_demo'\n",
    "    # Specify the filename\n",
    "    filename = \"comment_data_demo.json\"\n",
    "    print('Using demo...')\n",
    "else:\n",
    "    folder_path = r'C:\\Users\\Usuario\\Documents\\JupyterFolder\\unimi_files\\IR\\files_csv'\n",
    "    filename = \"comment_data.json\"\n",
    "\n",
    "# Construct the full file path\n",
    "file_path = os.path.join(folder_path, filename)\n",
    "\n",
    "# Read the JSON file containing the comment data\n",
    "with open(file_path, 'r') as f:\n",
    "    post_list = json.load(f)\n",
    "    \n",
    "# Print the number of comments before any formatting\n",
    "print(f'Amount of comments before any formatting: {len(post_list)}')\n",
    "\n",
    "# Convert the JSON data into a pandas DataFrame\n",
    "df = pd.json_normalize(post_list)\n",
    "\n",
    "if demo:\n",
    "    # Set the path for the original data directory\n",
    "    path_original_data = r'C:\\Users\\Usuario\\Documents\\JupyterFolder\\unimi_files\\IR\\files_csv\\version_demo'\n",
    "    # Save the DataFrame as a CSV file in the specified directory\n",
    "    df.to_csv(os.path.join(path_original_data, 'comment_data_demo.csv'), index=False)\n",
    "    rint('Using demo...')\n",
    "else:\n",
    "    path_original_data = r'C:\\Users\\Usuario\\Documents\\JupyterFolder\\unimi_files\\IR\\files_csv'\n",
    "    df.to_csv(os.path.join(path_original_data, 'comment_data.csv'), index=False)\n",
    "\n",
    "# Display the first row of the DataFrame\n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f531563",
   "metadata": {},
   "source": [
    "# CLEANING\n",
    "\n",
    "## Reading raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "6f144b6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "72651\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>user</th>\n",
       "      <th>comment</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>390478</td>\n",
       "      <td>Gloomhaven: Second Edition</td>\n",
       "      <td>amusedleg</td>\n",
       "      <td>Day 1 of the GH 2.0 campaign.  Can't wait.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id                       title       user  \\\n",
       "0  390478  Gloomhaven: Second Edition  amusedleg   \n",
       "\n",
       "                                      comment  rating  \n",
       "0  Day 1 of the GH 2.0 campaign.  Can't wait.     NaN  "
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "if demo:\n",
    "    # Set the path for the original data directory\n",
    "    path_original_data = r'C:\\Users\\Usuario\\Documents\\JupyterFolder\\unimi_files\\IR\\files_csv\\version_demo'\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(os.path.join(path_original_data, 'comment_data_demo.csv'), low_memory=False)\n",
    "    rint('Using demo...')\n",
    "else:\n",
    "    path_original_data = r'C:\\Users\\Usuario\\Documents\\JupyterFolder\\unimi_files\\IR\\files_csv'\n",
    "    df = pd.read_csv(os.path.join(path_original_data, 'comment_data.csv'), low_memory=False)\n",
    "\n",
    "print('[*]', len(df))    \n",
    "df.head(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fa118e67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100.0%\n",
      "18588\n",
      "1\n",
      "199.270062641977\n",
      "\n",
      "1326\n",
      "1\n",
      "0\n",
      "102      After just one play I get the feeling I have s...\n",
      "146      I really don’t get the hype around Heat, but t...\n",
      "183      An okay \"deck management” game with a relatabl...\n",
      "326      Update: After some more plays I feel that some...\n",
      "435      [imageID=6940449small inline] This really feel...\n",
      "                               ...                        \n",
      "72410    The character progression system is very inter...\n",
      "72507    These are thoughts from a single play through ...\n",
      "72515    This is pure a take that game! don't try to \"p...\n",
      "72566    Too long with 2P. Better with 3P, but the card...\n",
      "72593    Review: Highly interactive, tactical, and stre...\n",
      "Name: comment, Length: 1326, dtype: object\n",
      "[*] 72635\n"
     ]
    }
   ],
   "source": [
    "# Print some statistics of the 'comment' field\n",
    "\n",
    "# Calculate the percentage of non-null comments\n",
    "comment_percentage = round(df.comment.notnull().mean() * 100, 2)\n",
    "print(str(comment_percentage) + '%')\n",
    "\n",
    "# Calculate the maximum, minimum, and mean length of comments\n",
    "max_length = df.comment.str.len().max()\n",
    "min_length = df.comment.str.len().min()\n",
    "mean_length = df.comment.str.len().mean()\n",
    "print(max_length)\n",
    "print(min_length)\n",
    "print(mean_length)\n",
    "print()\n",
    "\n",
    "# Search the number of comments containing searched words within the text of the message\n",
    "pattern = \"random\"\n",
    "\n",
    "# Count comments containing the search pattern\n",
    "contains_pattern = df.comment.str.contains(pattern, na=False).sum()\n",
    "\n",
    "# Count comments starting with the search pattern\n",
    "starts_with_pattern = df.comment.str.startswith(pattern, na=False).sum()\n",
    "\n",
    "# Count comments exactly matching the search pattern\n",
    "exact_match_pattern = df.comment.str.fullmatch(pattern, na=False).sum()\n",
    "\n",
    "print(contains_pattern)\n",
    "print(starts_with_pattern)\n",
    "print(exact_match_pattern)\n",
    "\n",
    "# Filter out rows with null comments and reset the index\n",
    "df = df[df.comment.notnull()]\n",
    "df.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the first messages that contain the pattern\n",
    "matching_comments = df.loc[df.comment.str.contains(pattern, na=False), 'comment']\n",
    "print(matching_comments)\n",
    "\n",
    "print('[*]', len(df))    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b879a8a",
   "metadata": {},
   "source": [
    "## Filtering the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "5bd3c377",
   "metadata": {},
   "outputs": [],
   "source": [
    "from guess_language import guess_language\n",
    "import enchant\n",
    "import string\n",
    "import re\n",
    "\n",
    "# Function to check if a comment is in English\n",
    "def is_english_batch(batch):\n",
    "    # Create a batch of processed texts\n",
    "    processed_texts = batch['comment'].str.lower().str.findall(r\"[a-zA-Z0-9']+\")\n",
    "\n",
    "    # Create an English dictionary\n",
    "    english_dictionary = enchant.Dict(\"en_US\")\n",
    "\n",
    "    # Check if any comment in the batch is in English\n",
    "    is_english = processed_texts.apply(lambda text: sum(english_dictionary.check(word) for word in text) >= len(text) / 2)\n",
    "\n",
    "    # Return a boolean Series indicating if each comment is in English\n",
    "    return is_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "9c70f1bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 73/73 [03:37<00:00,  2.98s/it]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>user</th>\n",
       "      <th>comment</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>390478.0</td>\n",
       "      <td>Gloomhaven: Second Edition</td>\n",
       "      <td>amusedleg</td>\n",
       "      <td>Day 1 of the GH 2.0 campaign.  Can't wait.</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>390478.0</td>\n",
       "      <td>Gloomhaven: Second Edition</td>\n",
       "      <td>bark</td>\n",
       "      <td>BGCJ made me do it. Stop making fake dungeon c...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>390478.0</td>\n",
       "      <td>Gloomhaven: Second Edition</td>\n",
       "      <td>Brefs</td>\n",
       "      <td>Cant wait for It, thanks for the amazing job s...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>390478.0</td>\n",
       "      <td>Gloomhaven: Second Edition</td>\n",
       "      <td>Dali187</td>\n",
       "      <td>A perfect non greed driven game made even more...</td>\n",
       "      <td>10.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>390478.0</td>\n",
       "      <td>Gloomhaven: Second Edition</td>\n",
       "      <td>DJ_Tsaladi_Tjatekok</td>\n",
       "      <td>Nem vagyok egy Homályrév-rajongó, de ha már me...</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    0        id                       title                 user  \\\n",
       "0 NaN  390478.0  Gloomhaven: Second Edition            amusedleg   \n",
       "1 NaN  390478.0  Gloomhaven: Second Edition                 bark   \n",
       "2 NaN  390478.0  Gloomhaven: Second Edition                Brefs   \n",
       "3 NaN  390478.0  Gloomhaven: Second Edition              Dali187   \n",
       "4 NaN  390478.0  Gloomhaven: Second Edition  DJ_Tsaladi_Tjatekok   \n",
       "\n",
       "                                             comment  rating  \n",
       "0         Day 1 of the GH 2.0 campaign.  Can't wait.     NaN  \n",
       "1  BGCJ made me do it. Stop making fake dungeon c...     1.0  \n",
       "2  Cant wait for It, thanks for the amazing job s...    10.0  \n",
       "3  A perfect non greed driven game made even more...    10.0  \n",
       "4  Nem vagyok egy Homályrév-rajongó, de ha már me...     NaN  "
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import display, HTML\n",
    "from alive_progress import alive_bar\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import time\n",
    "import sys\n",
    "\n",
    "# Batch processing\n",
    "batch_size = 1000  # Number of rows to process in each batch\n",
    "num_rows = len(df)\n",
    "result = pd.Series([], dtype='float64')  # Store the results\n",
    "\n",
    "# Calculate the number of batches\n",
    "num_batches = (num_rows // batch_size) + 1\n",
    "\n",
    "# Initialize a progress bar\n",
    "with tqdm(total=num_batches, ncols=num_batches) as pbar:\n",
    "    # Process each batch\n",
    "    for i in range(0, num_rows, batch_size):\n",
    "        # Extract a batch of rows from the DataFrame\n",
    "        batch = df.iloc[i:i+batch_size]\n",
    "        \n",
    "        # Filter out non-English rows in the batch\n",
    "        batch_english = batch.loc[is_english_batch(batch)]\n",
    "        \n",
    "        # Concatenate the English rows to the result\n",
    "        result = pd.concat([result, batch_english])\n",
    "        \n",
    "        # Update the progress bar\n",
    "        pbar.update(1)\n",
    "\n",
    "# Reset the index of the resulting DataFrame\n",
    "result.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the updated DataFrame\n",
    "result.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "9607c93b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current database: 66267\n",
      "Original database: 72635\n",
      "Difference: 6368\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>user</th>\n",
       "      <th>comment</th>\n",
       "      <th>rating</th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>390478.0</td>\n",
       "      <td>Gloomhaven: Second Edition</td>\n",
       "      <td>Fuzzel</td>\n",
       "      <td>Unnötige Geldmache mit der erfolgreichen Marke.</td>\n",
       "      <td>1.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>366013.0</td>\n",
       "      <td>Heat: Pedal to the Metal</td>\n",
       "      <td>a2greg</td>\n",
       "      <td>nyp</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>366013.0</td>\n",
       "      <td>Heat: Pedal to the Metal</td>\n",
       "      <td>Abri</td>\n",
       "      <td>56x87mm cards (330pcs)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>366013.0</td>\n",
       "      <td>Heat: Pedal to the Metal</td>\n",
       "      <td>alexbatbee</td>\n",
       "      <td>zatu</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>366013.0</td>\n",
       "      <td>Heat: Pedal to the Metal</td>\n",
       "      <td>ANDREWSOFT</td>\n",
       "      <td>Jugadas varias partidas en solitario con el mó...</td>\n",
       "      <td>8.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         id                       title        user  \\\n",
       "0  390478.0  Gloomhaven: Second Edition      Fuzzel   \n",
       "1  366013.0    Heat: Pedal to the Metal      a2greg   \n",
       "2  366013.0    Heat: Pedal to the Metal        Abri   \n",
       "3  366013.0    Heat: Pedal to the Metal  alexbatbee   \n",
       "4  366013.0    Heat: Pedal to the Metal  ANDREWSOFT   \n",
       "\n",
       "                                             comment  rating   0  \n",
       "0    Unnötige Geldmache mit der erfolgreichen Marke.     1.0 NaN  \n",
       "1                                                nyp     NaN NaN  \n",
       "2                             56x87mm cards (330pcs)     NaN NaN  \n",
       "3                                               zatu     NaN NaN  \n",
       "4  Jugadas varias partidas en solitario con el mó...     8.2 NaN  "
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Print the size of each database\n",
    "print('Current database:', len(result))\n",
    "print('Original database:', len(df))\n",
    "print('Difference:', len(df)-len(result))\n",
    "\n",
    "# Assuming you have two DataFrames: df1 and df2 representing the two databases\n",
    "df1 = df\n",
    "# print('Check.')\n",
    "df2 = result\n",
    "# print('Check.')\n",
    "\n",
    "# Find rows with differing 'comment' in df1 compared to df2\n",
    "diff_df1 = df1[~df1['comment'].isin(df2['comment'])]\n",
    "\n",
    "# Find rows with differing 'comment' in df2 compared to df1\n",
    "diff_df2 = df2[~df2['comment'].isin(df1['comment'])]\n",
    "\n",
    "# Concatenate the differing rows into a single DataFrame\n",
    "diff_combined = pd.concat([diff_df1, diff_df2])\n",
    "\n",
    "# Reset the index of the resulting DataFrame\n",
    "diff_combined.reset_index(drop=True, inplace=True)\n",
    "\n",
    "# Print the differences\n",
    "diff_combined.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "b32685aa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original database: 66267\n",
      "Current database: 45247\n"
     ]
    }
   ],
   "source": [
    "# Add a new column with the length of each comment\n",
    "result['text_length'] = result['comment'].apply(lambda x: len(x))  \n",
    "\n",
    "# Add a new column with the word count of each comment\n",
    "result['word_count'] = result['comment'].apply(lambda x: len(x.split())) \n",
    "\n",
    "# Filter out rows with word count less than or equal to 5\n",
    "print('Original database:', len(result))\n",
    "result = result[result['word_count'] > 5]  \n",
    "\n",
    "# Print the size of each database\n",
    "print('Current database:', len(result))\n",
    "\n",
    "# Drop the first column (assumed to be unnecessary)\n",
    "result = result.drop(result.columns[0], axis=1)  \n",
    "\n",
    "# Print the first 5 rows of the resulting DataFrame\n",
    "result.head(5)  \n",
    "\n",
    "# Save the pre-processed DataFrame to a CSV file\n",
    "if demo:\n",
    "    result.to_csv(os.path.join(path_original_data, 'pre_processed_comment_data_demo.csv'), index=False)\n",
    "else:\n",
    "    result.to_csv(os.path.join(path_original_data, 'pre_processed_comment_data.csv'), index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aca7f5b3",
   "metadata": {},
   "source": [
    "# PREPROCESS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "360ff666",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary modules\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "# Set the display option to show all columns in pandas DataFrame\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "if demo:\n",
    "    # Set the path for the original data directory\n",
    "    path_original_data = r'C:\\Users\\Usuario\\Documents\\JupyterFolder\\unimi_files\\IR\\files_csv\\version_demo'\n",
    "    # Construct the file path to the CSV file\n",
    "    csv_file_path = os.path.join(path_original_data, 'pre_processed_comment_data_demo.csv')\n",
    "    print('Using demo...')\n",
    "else:\n",
    "    path_original_data = r'C:\\Users\\Usuario\\Documents\\JupyterFolder\\unimi_files\\IR\\files_csv'\n",
    "    csv_file_path = os.path.join(path_original_data, 'pre_processed_comment_data.csv')\n",
    "\n",
    "# Read the CSV file into a DataFrame\n",
    "df = pd.read_csv(csv_file_path, low_memory=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e47da6c6",
   "metadata": {},
   "source": [
    "## Punctuation Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "acad253b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import string\n",
    "\n",
    "# Function to remove punctuation from a text\n",
    "def remove_punctuation(text):\n",
    "    # Create a set of allowed characters (letters, numbers, and space)\n",
    "    allowed_chars = set(string.ascii_letters + string.digits + ' ')\n",
    "    \n",
    "    # Remove punctuation characters not in the allowed set\n",
    "    processed_text = ''.join(char for char in text if char in allowed_chars)\n",
    "    \n",
    "    return processed_text\n",
    "\n",
    "# Apply the remove_punctuation() function to the 'comment' column and store the result in a new column 'processed_comment'\n",
    "df['processed_comment'] = df['comment'].apply(remove_punctuation)\n",
    "\n",
    "# Lower case all the messages\n",
    "df['processed_comment'] = df['processed_comment'].str.lower()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67e41eff",
   "metadata": {},
   "source": [
    "## Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "d3dd8a5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# Function to tokenize a text\n",
    "def tokenization(text):\n",
    "    # Split the text on spaces to create tokens\n",
    "    tokens = text.split()\n",
    "    \n",
    "    return tokens\n",
    "\n",
    "# Apply the tokenization() function to the 'processed_comment' column and store the result in a new column 'comment_tokenized'\n",
    "df['comment_tokenized'] = df['processed_comment'].apply(lambda x: tokenization(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dc435a4",
   "metadata": {},
   "source": [
    "## Stopword Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "9dccbe94",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\"]\n"
     ]
    }
   ],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "import nltk\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "\n",
    "# Download the required NLTK resources (uncomment if needed)\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "\n",
    "# Stop words present in the library\n",
    "stopwords = nltk.corpus.stopwords.words('english')\n",
    "print(stopwords[0:10])\n",
    "\n",
    "# Defining the function to remove stopwords from tokenized text\n",
    "def remove_stopwords(text):\n",
    "    output= [i for i in text if i not in stopwords]\n",
    "    return output\n",
    "\n",
    "# Applying the function\n",
    "df['comment_key_words']= df['comment_tokenized'].apply(lambda x:remove_stopwords(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7cf6615e",
   "metadata": {},
   "source": [
    "## Stemming"
   ]
  },
  {
   "cell_type": "raw",
   "id": "e1e1aa5c",
   "metadata": {},
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "\n",
    "# Defining the object for stemming\n",
    "porter_stemmer = PorterStemmer()\n",
    "\n",
    "# Defining a function for stemming\n",
    "def stemming(text):\n",
    "    stem_text = [porter_stemmer.stem(word) for word in text]\n",
    "\n",
    "    return stem_text\n",
    "\n",
    "df['comment_stemmed']= df['comment_key_words'].apply(lambda x: stemming(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "174db225",
   "metadata": {},
   "source": [
    "## Lemmatization"
   ]
  },
  {
   "cell_type": "raw",
   "id": "c1fff780",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "import nltk\n",
    "# nltk.download('wordnet')\n",
    "# nltk.download('omw-1.4')\n",
    "\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# Defining the object for Lemmatization\n",
    "wordnet_lemmatizer = WordNetLemmatizer()\n",
    "\n",
    "# Defining the function for lemmatization\n",
    "def lemmatizer(text):\n",
    "    lemm_text = [wordnet_lemmatizer.lemmatize(word) for word in text]\n",
    "    \n",
    "    return lemm_text\n",
    "\n",
    "df['comment_lemmatized']= df['comment_key_words'].apply(lambda x:lemmatizer(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23db142c",
   "metadata": {},
   "source": [
    "## Gensim preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "dae5839c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "import nltk\n",
    "import json\n",
    "\n",
    "np.random.seed(400)\n",
    "\n",
    "# Download the required NLTK resource (uncomment if needed)\n",
    "# nltk.download('wordnet')\n",
    "\n",
    "reference_sheet = {}  # Dictionary to store word reference sheet\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\")\n",
    "\n",
    "# Function to lemmatize and stem a word\n",
    "def lemmatize_stemming(text):\n",
    "    return stemmer.stem(WordNetLemmatizer().lemmatize(text, pos='v'))\n",
    "\n",
    "# Tokenize, lemmatize, and filter stopwords\n",
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in STOPWORDS and len(token) > 2:\n",
    "            word = lemmatize_stemming(token)\n",
    "            if word in reference_sheet:\n",
    "                if token not in reference_sheet[word]:\n",
    "                    reference_sheet[word].append(token)\n",
    "            else:\n",
    "                reference_sheet[word] = [token]\n",
    "            result.append(word)\n",
    "    return result\n",
    "\n",
    "# Tokenize, lemmatize, and filter verbs\n",
    "def preprocess_verbs(text):\n",
    "    text = gensim.utils.simple_preprocess(text)\n",
    "    tagged_tokens = nltk.pos_tag(text)\n",
    "    filtered_tokens = [token for token, pos_tag in tagged_tokens if pos_tag not in ['VB', 'VBD', 'VBG', 'VBN', 'VBP', 'VBZ']]\n",
    "    \n",
    "    result = []\n",
    "    for token in filtered_tokens:\n",
    "        if token not in STOPWORDS and len(token) > 2:\n",
    "            result.append(lemmatize_stemming(token))\n",
    "    return result\n",
    "\n",
    "# print('Start.')\n",
    "df['gensim_comment'] = df['comment'].apply(preprocess)\n",
    "# print('Next.')\n",
    "df['gensim_comment_verbs'] = df['comment'].apply(preprocess_verbs)\n",
    "# print('Finish.')\n",
    "\n",
    "# Save reference sheet as a JSON file\n",
    "json_data = json.dumps(reference_sheet)\n",
    "with open('reference_sheet.json', 'w') as file:\n",
    "    file.write(json_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aadb7aae",
   "metadata": {},
   "source": [
    "## Restructring the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "e522468b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "False\n"
     ]
    }
   ],
   "source": [
    "# At this point is necesary to check if the variable 'demo' has not being changed\n",
    "print(demo)\n",
    "#demo = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "78769784",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['id', 'title', 'user', 'comment', 'rating', 'text_length', 'word_count', 'processed_comment', 'comment_tokenized', 'comment_key_words', 'gensim_comment', 'gensim_comment_verbs'] \n",
      "\n",
      "Original database: 40175\n",
      "Current database: 40175\n",
      "242.03462352209084\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>user</th>\n",
       "      <th>comment</th>\n",
       "      <th>rating</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>processed_comment</th>\n",
       "      <th>comment_tokenized</th>\n",
       "      <th>comment_key_words</th>\n",
       "      <th>gensim_comment</th>\n",
       "      <th>gensim_comment_verbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16698</th>\n",
       "      <td>295947.0</td>\n",
       "      <td>Cascadia</td>\n",
       "      <td>Urtho</td>\n",
       "      <td>I have a feeling this would fill the same nich...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>171</td>\n",
       "      <td>37</td>\n",
       "      <td>i have a feeling this would fill the same nich...</td>\n",
       "      <td>['i', 'have', 'a', 'feeling', 'this', 'would',...</td>\n",
       "      <td>['feeling', 'would', 'fill', 'niche', 'shelf',...</td>\n",
       "      <td>['feel', 'nich', 'shelf', 'park', 'amaz', 'lon...</td>\n",
       "      <td>['feel', 'nich', 'shelf', 'park', 'amaz', 'lon...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1326</th>\n",
       "      <td>331106.0</td>\n",
       "      <td>The Witcher: Old World</td>\n",
       "      <td>ahazperutz</td>\n",
       "      <td>Figure set for Witcher fans (you can even play...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>55</td>\n",
       "      <td>10</td>\n",
       "      <td>figure set for witcher fans you can even play ...</td>\n",
       "      <td>['figure', 'set', 'for', 'witcher', 'fans', 'y...</td>\n",
       "      <td>['figure', 'set', 'witcher', 'fans', 'even', '...</td>\n",
       "      <td>['figur', 'set', 'witcher', 'fan', 'play', 'ga...</td>\n",
       "      <td>['figur', 'witcher', 'fan', 'game']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>366013.0</td>\n",
       "      <td>Heat: Pedal to the Metal</td>\n",
       "      <td>jonathangmeyer</td>\n",
       "      <td>Having now played this, I can see where all th...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>589</td>\n",
       "      <td>101</td>\n",
       "      <td>having now played this i can see where all the...</td>\n",
       "      <td>['having', 'now', 'played', 'this', 'i', 'can'...</td>\n",
       "      <td>['played', 'see', 'hype', 'comes', 'solid', 'g...</td>\n",
       "      <td>['have', 'play', 'hype', 'come', 'solid', 'gam...</td>\n",
       "      <td>['hype', 'solid', 'game', 'easi', 'gear', 'pre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15797</th>\n",
       "      <td>295947.0</td>\n",
       "      <td>Cascadia</td>\n",
       "      <td>jjvvhh</td>\n",
       "      <td>Abstract 1. Family 5. 2022 Spiel des Jahres</td>\n",
       "      <td>NaN</td>\n",
       "      <td>43</td>\n",
       "      <td>8</td>\n",
       "      <td>abstract 1 family 5 2022 spiel des jahres</td>\n",
       "      <td>['abstract', '1', 'family', '5', '2022', 'spie...</td>\n",
       "      <td>['abstract', '1', 'family', '5', '2022', 'spie...</td>\n",
       "      <td>['abstract', 'famili', 'spiel', 'des', 'jahr']</td>\n",
       "      <td>['abstract', 'famili', 'spiel', 'des', 'jahr']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2905</th>\n",
       "      <td>342942.0</td>\n",
       "      <td>Ark Nova</td>\n",
       "      <td>mil05006</td>\n",
       "      <td>This game is a ton of fun, though the endgame ...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>189</td>\n",
       "      <td>38</td>\n",
       "      <td>this game is a ton of fun though the endgame c...</td>\n",
       "      <td>['this', 'game', 'is', 'a', 'ton', 'of', 'fun'...</td>\n",
       "      <td>['game', 'ton', 'fun', 'though', 'endgame', 'c...</td>\n",
       "      <td>['game', 'ton', 'fun', 'endgam', 'come', 'pret...</td>\n",
       "      <td>['game', 'ton', 'fun', 'endgam', 'pretti', 'ab...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                     title            user  \\\n",
       "16698  295947.0                  Cascadia           Urtho   \n",
       "1326   331106.0    The Witcher: Old World      ahazperutz   \n",
       "312    366013.0  Heat: Pedal to the Metal  jonathangmeyer   \n",
       "15797  295947.0                  Cascadia          jjvvhh   \n",
       "2905   342942.0                  Ark Nova        mil05006   \n",
       "\n",
       "                                                 comment  rating  text_length  \\\n",
       "16698  I have a feeling this would fill the same nich...     6.0          171   \n",
       "1326   Figure set for Witcher fans (you can even play...     1.0           55   \n",
       "312    Having now played this, I can see where all th...     9.0          589   \n",
       "15797        Abstract 1. Family 5. 2022 Spiel des Jahres     NaN           43   \n",
       "2905   This game is a ton of fun, though the endgame ...     9.0          189   \n",
       "\n",
       "       word_count                                  processed_comment  \\\n",
       "16698          37  i have a feeling this would fill the same nich...   \n",
       "1326           10  figure set for witcher fans you can even play ...   \n",
       "312           101  having now played this i can see where all the...   \n",
       "15797           8          abstract 1 family 5 2022 spiel des jahres   \n",
       "2905           38  this game is a ton of fun though the endgame c...   \n",
       "\n",
       "                                       comment_tokenized  \\\n",
       "16698  ['i', 'have', 'a', 'feeling', 'this', 'would',...   \n",
       "1326   ['figure', 'set', 'for', 'witcher', 'fans', 'y...   \n",
       "312    ['having', 'now', 'played', 'this', 'i', 'can'...   \n",
       "15797  ['abstract', '1', 'family', '5', '2022', 'spie...   \n",
       "2905   ['this', 'game', 'is', 'a', 'ton', 'of', 'fun'...   \n",
       "\n",
       "                                       comment_key_words  \\\n",
       "16698  ['feeling', 'would', 'fill', 'niche', 'shelf',...   \n",
       "1326   ['figure', 'set', 'witcher', 'fans', 'even', '...   \n",
       "312    ['played', 'see', 'hype', 'comes', 'solid', 'g...   \n",
       "15797  ['abstract', '1', 'family', '5', '2022', 'spie...   \n",
       "2905   ['game', 'ton', 'fun', 'though', 'endgame', 'c...   \n",
       "\n",
       "                                          gensim_comment  \\\n",
       "16698  ['feel', 'nich', 'shelf', 'park', 'amaz', 'lon...   \n",
       "1326   ['figur', 'set', 'witcher', 'fan', 'play', 'ga...   \n",
       "312    ['have', 'play', 'hype', 'come', 'solid', 'gam...   \n",
       "15797     ['abstract', 'famili', 'spiel', 'des', 'jahr']   \n",
       "2905   ['game', 'ton', 'fun', 'endgam', 'come', 'pret...   \n",
       "\n",
       "                                    gensim_comment_verbs  \n",
       "16698  ['feel', 'nich', 'shelf', 'park', 'amaz', 'lon...  \n",
       "1326                 ['figur', 'witcher', 'fan', 'game']  \n",
       "312    ['hype', 'solid', 'game', 'easi', 'gear', 'pre...  \n",
       "15797     ['abstract', 'famili', 'spiel', 'des', 'jahr']  \n",
       "2905   ['game', 'ton', 'fun', 'endgam', 'pretti', 'ab...  "
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Get the list of column names\n",
    "columns = list(df.columns)\n",
    "print(columns, '\\n')\n",
    "\n",
    "print('Original database:', len(df))\n",
    "# Filter the DataFrame based on the length of 'gensim_comment' column\n",
    "df = df[df['gensim_comment'].map(lambda d: len(d)) >= 5]\n",
    "df = df.reset_index(drop=True)\n",
    "\n",
    "# Print the size of each database\n",
    "print('Current database:', len(df))\n",
    "\n",
    "\n",
    "# Calculate the average length of 'gensim_comment' column\n",
    "average_length = df['gensim_comment'].apply(lambda x: len(x)).mean()\n",
    "print(average_length)\n",
    "\n",
    "if demo:\n",
    "     # Set the path for the original data directory\n",
    "    path_original_data = r'C:\\Users\\Usuario\\Documents\\JupyterFolder\\unimi_files\\IR\\files_csv\\version_demo'\n",
    "    # Save the DataFrame to a CSV file\n",
    "    df.to_csv(os.path.join(path_original_data, 'post_processed_comment_data_demo.csv'), index=False)\n",
    "    print('Using demo...')\n",
    "else:\n",
    "    path_original_data = r'C:\\Users\\Usuario\\Documents\\JupyterFolder\\unimi_files\\IR\\files_csv'\n",
    "    df.to_csv(os.path.join(path_original_data, 'post_processed_comment_data.csv'), index=False)\n",
    "\n",
    "# Display a sample of 5 rows from the DataFrame\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "ab1836cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>user</th>\n",
       "      <th>comment</th>\n",
       "      <th>rating</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>processed_comment</th>\n",
       "      <th>comment_tokenized</th>\n",
       "      <th>comment_key_words</th>\n",
       "      <th>gensim_comment</th>\n",
       "      <th>gensim_comment_verbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15866</th>\n",
       "      <td>295947.0</td>\n",
       "      <td>Cascadia</td>\n",
       "      <td>Kankui</td>\n",
       "      <td>Purchased from GameNerdz, Nerdz Day sale - $22.</td>\n",
       "      <td>8.0</td>\n",
       "      <td>47</td>\n",
       "      <td>8</td>\n",
       "      <td>purchased from gamenerdz nerdz day sale  22</td>\n",
       "      <td>['purchased', 'from', 'gamenerdz', 'nerdz', 'd...</td>\n",
       "      <td>['purchased', 'gamenerdz', 'nerdz', 'day', 'sa...</td>\n",
       "      <td>['purchas', 'gamenerdz', 'nerdz', 'day', 'sale']</td>\n",
       "      <td>['gamenerdz', 'nerdz', 'day', 'sale']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39243</th>\n",
       "      <td>192135.0</td>\n",
       "      <td>Too Many Bones</td>\n",
       "      <td>fiatkid55</td>\n",
       "      <td>Quite a unique game. Tense, building difficult...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>221</td>\n",
       "      <td>38</td>\n",
       "      <td>quite a unique game tense building difficulty ...</td>\n",
       "      <td>['quite', 'a', 'unique', 'game', 'tense', 'bui...</td>\n",
       "      <td>['quite', 'unique', 'game', 'tense', 'building...</td>\n",
       "      <td>['uniqu', 'game', 'tens', 'build', 'difficulti...</td>\n",
       "      <td>['uniqu', 'game', 'tens', 'difficulti', 'tyran...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21533</th>\n",
       "      <td>169786.0</td>\n",
       "      <td>Scythe</td>\n",
       "      <td>PolterGhost</td>\n",
       "      <td>This is a miniature 4X game, basically reducin...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>612</td>\n",
       "      <td>103</td>\n",
       "      <td>this is a miniature 4x game basically reducing...</td>\n",
       "      <td>['this', 'is', 'a', 'miniature', '4x', 'game',...</td>\n",
       "      <td>['miniature', '4x', 'game', 'basically', 'redu...</td>\n",
       "      <td>['miniatur', 'game', 'basic', 'reduc', 'explor...</td>\n",
       "      <td>['miniatur', 'game', 'basic', 'explor', 'event...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29035</th>\n",
       "      <td>255984.0</td>\n",
       "      <td>Sleeping Gods</td>\n",
       "      <td>Stonebeard</td>\n",
       "      <td>It can't be a 10 because I will eventually hav...</td>\n",
       "      <td>9.5</td>\n",
       "      <td>371</td>\n",
       "      <td>71</td>\n",
       "      <td>it cant be a 10 because i will eventually have...</td>\n",
       "      <td>['it', 'cant', 'be', 'a', '10', 'because', 'i'...</td>\n",
       "      <td>['cant', '10', 'eventually', 'everywhere', 'fi...</td>\n",
       "      <td>['eventu', 'game', 'teach', 'readi', 'second',...</td>\n",
       "      <td>['eventu', 'game', 'readi', 'second', 'game', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14203</th>\n",
       "      <td>205637.0</td>\n",
       "      <td>Arkham Horror: The Card Game</td>\n",
       "      <td>the_horror</td>\n",
       "      <td>This quickly became one our top 3 favorite co-...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>110</td>\n",
       "      <td>20</td>\n",
       "      <td>this quickly became one our top 3 favorite coo...</td>\n",
       "      <td>['this', 'quickly', 'became', 'one', 'our', 't...</td>\n",
       "      <td>['quickly', 'became', 'one', 'top', '3', 'favo...</td>\n",
       "      <td>['quick', 'favorit', 'game', 'fantast', 'desig...</td>\n",
       "      <td>['quick', 'favorit', 'game', 'fantast', 'desig...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                         title         user  \\\n",
       "15866  295947.0                      Cascadia       Kankui   \n",
       "39243  192135.0                Too Many Bones    fiatkid55   \n",
       "21533  169786.0                        Scythe  PolterGhost   \n",
       "29035  255984.0                 Sleeping Gods   Stonebeard   \n",
       "14203  205637.0  Arkham Horror: The Card Game   the_horror   \n",
       "\n",
       "                                                 comment  rating  text_length  \\\n",
       "15866    Purchased from GameNerdz, Nerdz Day sale - $22.     8.0           47   \n",
       "39243  Quite a unique game. Tense, building difficult...     9.0          221   \n",
       "21533  This is a miniature 4X game, basically reducin...     7.0          612   \n",
       "29035  It can't be a 10 because I will eventually hav...     9.5          371   \n",
       "14203  This quickly became one our top 3 favorite co-...     9.0          110   \n",
       "\n",
       "       word_count                                  processed_comment  \\\n",
       "15866           8        purchased from gamenerdz nerdz day sale  22   \n",
       "39243          38  quite a unique game tense building difficulty ...   \n",
       "21533         103  this is a miniature 4x game basically reducing...   \n",
       "29035          71  it cant be a 10 because i will eventually have...   \n",
       "14203          20  this quickly became one our top 3 favorite coo...   \n",
       "\n",
       "                                       comment_tokenized  \\\n",
       "15866  ['purchased', 'from', 'gamenerdz', 'nerdz', 'd...   \n",
       "39243  ['quite', 'a', 'unique', 'game', 'tense', 'bui...   \n",
       "21533  ['this', 'is', 'a', 'miniature', '4x', 'game',...   \n",
       "29035  ['it', 'cant', 'be', 'a', '10', 'because', 'i'...   \n",
       "14203  ['this', 'quickly', 'became', 'one', 'our', 't...   \n",
       "\n",
       "                                       comment_key_words  \\\n",
       "15866  ['purchased', 'gamenerdz', 'nerdz', 'day', 'sa...   \n",
       "39243  ['quite', 'unique', 'game', 'tense', 'building...   \n",
       "21533  ['miniature', '4x', 'game', 'basically', 'redu...   \n",
       "29035  ['cant', '10', 'eventually', 'everywhere', 'fi...   \n",
       "14203  ['quickly', 'became', 'one', 'top', '3', 'favo...   \n",
       "\n",
       "                                          gensim_comment  \\\n",
       "15866   ['purchas', 'gamenerdz', 'nerdz', 'day', 'sale']   \n",
       "39243  ['uniqu', 'game', 'tens', 'build', 'difficulti...   \n",
       "21533  ['miniatur', 'game', 'basic', 'reduc', 'explor...   \n",
       "29035  ['eventu', 'game', 'teach', 'readi', 'second',...   \n",
       "14203  ['quick', 'favorit', 'game', 'fantast', 'desig...   \n",
       "\n",
       "                                    gensim_comment_verbs  \n",
       "15866              ['gamenerdz', 'nerdz', 'day', 'sale']  \n",
       "39243  ['uniqu', 'game', 'tens', 'difficulti', 'tyran...  \n",
       "21533  ['miniatur', 'game', 'basic', 'explor', 'event...  \n",
       "29035  ['eventu', 'game', 'readi', 'second', 'game', ...  \n",
       "14203  ['quick', 'favorit', 'game', 'fantast', 'desig...  "
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import json\n",
    "import os\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Set the maximum number of columns to display\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "if demo:\n",
    "    # Set the path for the original data directory\n",
    "    path_original_data = r'C:\\Users\\Usuario\\Documents\\JupyterFolder\\unimi_files\\IR\\files_csv\\version_demo'\n",
    "    # Read the CSV file into a DataFrame\n",
    "    df = pd.read_csv(os.path.join(path_original_data, 'post_processed_comment_data_demo.csv'), low_memory=False)\n",
    "    print('Using demo...')\n",
    "else:\n",
    "    path_original_data = r'C:\\Users\\Usuario\\Documents\\JupyterFolder\\unimi_files\\IR\\files_csv'\n",
    "    df = pd.read_csv(os.path.join(path_original_data, 'post_processed_comment_data.csv'), low_memory=False)\n",
    "\n",
    "# Display a sample of 10 rows from the DataFrame\n",
    "df.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "9919f5b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "40175\n",
      "\n",
      "1453\n",
      "1305\n",
      "616\n",
      "1528\n",
      "437\n",
      "41\n",
      "\n",
      "569\n",
      "1050\n",
      "3111\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>title</th>\n",
       "      <th>user</th>\n",
       "      <th>comment</th>\n",
       "      <th>rating</th>\n",
       "      <th>text_length</th>\n",
       "      <th>word_count</th>\n",
       "      <th>processed_comment</th>\n",
       "      <th>comment_tokenized</th>\n",
       "      <th>comment_key_words</th>\n",
       "      <th>gensim_comment</th>\n",
       "      <th>gensim_comment_verbs</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28508</th>\n",
       "      <td>255984.0</td>\n",
       "      <td>Sleeping Gods</td>\n",
       "      <td>EdwardZ</td>\n",
       "      <td>I pretty much love everything I have from Red ...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>597</td>\n",
       "      <td>107</td>\n",
       "      <td>i pretty much love everything i have from red ...</td>\n",
       "      <td>['i', 'pretty', 'much', 'love', 'everything', ...</td>\n",
       "      <td>['pretty', 'much', 'love', 'everything', 'red'...</td>\n",
       "      <td>['pretti', 'love', 'red', 'raven', 'game', 're...</td>\n",
       "      <td>['pretti', 'love', 'red', 'raven', 'game', 'pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25453</th>\n",
       "      <td>285774.0</td>\n",
       "      <td>Marvel Champions: The Card Game</td>\n",
       "      <td>rolfisrolf</td>\n",
       "      <td>FFG is running out of ideas. They've taken ele...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>171</td>\n",
       "      <td>31</td>\n",
       "      <td>ffg is running out of ideas theyve taken eleme...</td>\n",
       "      <td>['ffg', 'is', 'running', 'out', 'of', 'ideas',...</td>\n",
       "      <td>['ffg', 'running', 'ideas', 'theyve', 'taken',...</td>\n",
       "      <td>['ffg', 'run', 'idea', 'take', 'element', 'pre...</td>\n",
       "      <td>['ffg', 'idea', 'element', 'previous', 'lcgs',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37014</th>\n",
       "      <td>291457.0</td>\n",
       "      <td>Gloomhaven: Jaws of the Lion</td>\n",
       "      <td>fenwayfrank</td>\n",
       "      <td>This game is a revelation. This is my first ti...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>522</td>\n",
       "      <td>89</td>\n",
       "      <td>this game is a revelation this is my first tim...</td>\n",
       "      <td>['this', 'game', 'is', 'a', 'revelation', 'thi...</td>\n",
       "      <td>['game', 'revelation', 'first', 'time', 'combi...</td>\n",
       "      <td>['game', 'revel', 'time', 'combin', 'charact',...</td>\n",
       "      <td>['game', 'revel', 'time', 'charact', 'build', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22706</th>\n",
       "      <td>169786.0</td>\n",
       "      <td>Scythe</td>\n",
       "      <td>tbpinter</td>\n",
       "      <td>Ugh. Dry and boring. Sold.  Sigh...Giving it a...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>113</td>\n",
       "      <td>21</td>\n",
       "      <td>ugh dry and boring sold  sighgiving it a secon...</td>\n",
       "      <td>['ugh', 'dry', 'and', 'boring', 'sold', 'sighg...</td>\n",
       "      <td>['ugh', 'dry', 'boring', 'sold', 'sighgiving',...</td>\n",
       "      <td>['ugh', 'dri', 'bore', 'sell', 'sigh', 'give',...</td>\n",
       "      <td>['ugh', 'dri', 'bore', 'sigh', 'second', 'tri'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17466</th>\n",
       "      <td>169786.0</td>\n",
       "      <td>Scythe</td>\n",
       "      <td>Bjorne</td>\n",
       "      <td>Not a good euro. Not a good direct conflict ga...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>83</td>\n",
       "      <td>16</td>\n",
       "      <td>not a good euro not a good direct conflict gam...</td>\n",
       "      <td>['not', 'a', 'good', 'euro', 'not', 'a', 'good...</td>\n",
       "      <td>['good', 'euro', 'good', 'direct', 'conflict',...</td>\n",
       "      <td>['good', 'euro', 'good', 'direct', 'conflict',...</td>\n",
       "      <td>['good', 'euro', 'good', 'direct', 'conflict',...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             id                            title         user  \\\n",
       "28508  255984.0                    Sleeping Gods      EdwardZ   \n",
       "25453  285774.0  Marvel Champions: The Card Game   rolfisrolf   \n",
       "37014  291457.0     Gloomhaven: Jaws of the Lion  fenwayfrank   \n",
       "22706  169786.0                           Scythe     tbpinter   \n",
       "17466  169786.0                           Scythe       Bjorne   \n",
       "\n",
       "                                                 comment  rating  text_length  \\\n",
       "28508  I pretty much love everything I have from Red ...     4.0          597   \n",
       "25453  FFG is running out of ideas. They've taken ele...     2.0          171   \n",
       "37014  This game is a revelation. This is my first ti...    10.0          522   \n",
       "22706  Ugh. Dry and boring. Sold.  Sigh...Giving it a...     8.0          113   \n",
       "17466  Not a good euro. Not a good direct conflict ga...     5.0           83   \n",
       "\n",
       "       word_count                                  processed_comment  \\\n",
       "28508         107  i pretty much love everything i have from red ...   \n",
       "25453          31  ffg is running out of ideas theyve taken eleme...   \n",
       "37014          89  this game is a revelation this is my first tim...   \n",
       "22706          21  ugh dry and boring sold  sighgiving it a secon...   \n",
       "17466          16  not a good euro not a good direct conflict gam...   \n",
       "\n",
       "                                       comment_tokenized  \\\n",
       "28508  ['i', 'pretty', 'much', 'love', 'everything', ...   \n",
       "25453  ['ffg', 'is', 'running', 'out', 'of', 'ideas',...   \n",
       "37014  ['this', 'game', 'is', 'a', 'revelation', 'thi...   \n",
       "22706  ['ugh', 'dry', 'and', 'boring', 'sold', 'sighg...   \n",
       "17466  ['not', 'a', 'good', 'euro', 'not', 'a', 'good...   \n",
       "\n",
       "                                       comment_key_words  \\\n",
       "28508  ['pretty', 'much', 'love', 'everything', 'red'...   \n",
       "25453  ['ffg', 'running', 'ideas', 'theyve', 'taken',...   \n",
       "37014  ['game', 'revelation', 'first', 'time', 'combi...   \n",
       "22706  ['ugh', 'dry', 'boring', 'sold', 'sighgiving',...   \n",
       "17466  ['good', 'euro', 'good', 'direct', 'conflict',...   \n",
       "\n",
       "                                          gensim_comment  \\\n",
       "28508  ['pretti', 'love', 'red', 'raven', 'game', 're...   \n",
       "25453  ['ffg', 'run', 'idea', 'take', 'element', 'pre...   \n",
       "37014  ['game', 'revel', 'time', 'combin', 'charact',...   \n",
       "22706  ['ugh', 'dri', 'bore', 'sell', 'sigh', 'give',...   \n",
       "17466  ['good', 'euro', 'good', 'direct', 'conflict',...   \n",
       "\n",
       "                                    gensim_comment_verbs  \n",
       "28508  ['pretti', 'love', 'red', 'raven', 'game', 'pe...  \n",
       "25453  ['ffg', 'idea', 'element', 'previous', 'lcgs',...  \n",
       "37014  ['game', 'revel', 'time', 'charact', 'build', ...  \n",
       "22706  ['ugh', 'dri', 'bore', 'sigh', 'second', 'tri'...  \n",
       "17466  ['good', 'euro', 'good', 'direct', 'conflict',...  "
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(len(df))\n",
    "print()\n",
    "\n",
    "# Check the number of posts that contain specific words\n",
    "print(len(df[df.comment.str.contains('luck')]))\n",
    "print(len(df[df.comment.str.contains('random')]))\n",
    "print(len(df[df.comment.str.contains('boring')]))\n",
    "print(len(df[df.comment.str.contains('complex')]))\n",
    "print(len(df[df.comment.str.contains('complicated')]))\n",
    "print(len(df[df.comment.str.contains('bookkeeping')]))\n",
    "print()\n",
    "print(len(df[df.comment.str.contains('edition')]))\n",
    "print(len(df[df.comment.str.contains('version')]))\n",
    "print(len(df[df.comment.str.contains('expansion')]))\n",
    "\n",
    "# Display a sample of 5 rows from the DataFrame that contain the word 'boring'\n",
    "df[df.comment.str.contains('boring')].sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "baa51f57",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
